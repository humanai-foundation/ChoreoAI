{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code reference: https://github.com/Luizerko/ai_choreo/blob/master/pose_extraction/data_processing.ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "with open('raw_img_9085.json') as f:\n",
    "    output = json.load(f)\n",
    "\n",
    "print(len(output))\n",
    "print(output[0].keys())\n",
    "print(output[0]['idx'], output[1]['idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_per_frame = {}\n",
    "for frame in output:\n",
    "    image_id = int(frame['image_id'].split('.')[0])\n",
    "\n",
    "    try:\n",
    "        poses_per_frame[image_id] += 1\n",
    "    except:\n",
    "        poses_per_frame[image_id] = 1\n",
    "\n",
    "missing_frames = []\n",
    "for k in [*poses_per_frame.keys()][:-1]:\n",
    "    if poses_per_frame.get(k + 1) is None:\n",
    "        missing_frames.append(k + 1)\n",
    "\n",
    "print('Missing frames: {}\\n'.format(missing_frames))\n",
    "print('Possible number of people per frame: {}\\n'.format(np.unique([*poses_per_frame.values()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_instances = []\n",
    "more_instances = []\n",
    "for k, v in poses_per_frame.items():\n",
    "    if v > 2:\n",
    "        more_instances.append(k)\n",
    "    elif v < 2:\n",
    "        less_instances.append(k)\n",
    "print('Frames with 1 person: {}\\n'.format(less_instances))\n",
    "print('Frames with 3 people: {}'.format(more_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "axes = []\n",
    "color = ['red', 'blue', 'green']\n",
    "skeleton = [(0, 1), (0, 2), (0, 3), (1, 4), (2, 5), (3, 6), (4, 7), (5, 8), (6, 9), (7, 10),\n",
    "            (8, 11), (9, 12), (9, 13), (9, 14), (12, 15), (13, 16), (14, 17), (16, 18), (17, 19), \n",
    "            (18, 20), (19, 21), (20, 22), (21, 23)]\n",
    "\n",
    "indexes = [512, 513, 514]\n",
    "for i in range(len(indexes)):\n",
    "    subplot_number = 131 + i\n",
    "    axes.append(fig.add_subplot(subplot_number, projection=\"3d\"))\n",
    "    axes[i].set_xlim([-1.2, 1.2])\n",
    "    axes[i].set_ylim([-1.2, 1.2])\n",
    "    axes[i].set_zlim([-1.2, 1.2])\n",
    "\n",
    "    scatter_points = np.array(output[indexes[i]]['pred_xyz_jts'])\n",
    "    axes[i].scatter(scatter_points[:, 2], scatter_points[:, 0], -scatter_points[:, 1], color=color[i])\n",
    "\n",
    "    for (start, end) in skeleton:\n",
    "        xs = [scatter_points[start, 2], scatter_points[end, 2]]\n",
    "        ys = [scatter_points[start, 0], scatter_points[end, 0]]\n",
    "        zs = [-scatter_points[start, 1], -scatter_points[end, 1]]\n",
    "        axes[i].plot(xs, ys, zs, color='grey')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing frames, single person frames and 3 people frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_output = output.copy()\n",
    "wrong_instances = sorted(set(more_instances).union(set(less_instances)))\n",
    "\n",
    "for i in wrong_instances:\n",
    "    # Filtering frames with more than 2 people\n",
    "    if poses_per_frame[i] > 2:\n",
    "        scores = [filtered_output[i * 2]['score'], filtered_output[i * 2 + 1]['score'], filtered_output[i * 2 + 2]['score']]\n",
    "        index = np.argmin(scores)\n",
    "        \n",
    "        if index == 0:\n",
    "            filtered_output.pop(i * 2)\n",
    "        elif index == 1:\n",
    "            filtered_output.pop(i * 2 + 1)\n",
    "        else:\n",
    "            filtered_output.pop(i * 2 + 2)\n",
    "\n",
    "    # Enriching frames with only 1 person\n",
    "    elif poses_per_frame[i] < 2:\n",
    "        only_person = np.array(filtered_output[i * 2]['pred_xyz_jts'])\n",
    "        to_compare_1 = np.array(filtered_output[i * 2 - 1]['pred_xyz_jts'])\n",
    "        to_compare_2 = np.array(filtered_output[i * 2 - 2]['pred_xyz_jts'])\n",
    "        \n",
    "        distance_1 = np.sum(np.linalg.norm(only_person - to_compare_1))\n",
    "        distance_2 = np.sum(np.linalg.norm(only_person - to_compare_2))\n",
    "\n",
    "        if distance_1 > distance_2:\n",
    "            new_data = filtered_output[i * 2 - 1].copy()\n",
    "            new_data['image_id'] = filtered_output[i*2]['image_id']\n",
    "            filtered_output.insert(i * 2 + 1, new_data)\n",
    "        else:\n",
    "            new_data = filtered_output[i * 2 - 2].copy()\n",
    "            new_data['image_id'] = filtered_output[i * 2]['image_id']\n",
    "            filtered_output.insert(i * 2, new_data)\n",
    "        \n",
    "filtered_poses_per_frame = {}\n",
    "for frame in filtered_output:\n",
    "    image_id = int(frame['image_id'].split('.')[0])\n",
    "    \n",
    "    try:\n",
    "        filtered_poses_per_frame[image_id] += 1\n",
    "    except:\n",
    "        filtered_poses_per_frame[image_id] = 1\n",
    "print('Possible number of people per frame: {}\\n'.format(np.unique([*filtered_poses_per_frame.values()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['animation.embed_limit'] = 100\n",
    "\n",
    "def animation(filtered_output, np_flag=False, interval=100):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.set_xlim([-1.2, 1.2])\n",
    "    ax.set_ylim([-1.2, 1.2])\n",
    "    ax.set_zlim([-1.2, 1.2])\n",
    "    \n",
    "    scatt1 = ax.scatter([], [], [], color='red')\n",
    "    lines1 = [ax.plot([], [], [], 'gray')[0] for _ in skeleton]\n",
    "    \n",
    "    scatt2 = ax.scatter([], [], [], color='blue')\n",
    "    lines2 = [ax.plot([], [], [], 'gray')[0] for _ in skeleton]\n",
    "\n",
    "    if np_flag:\n",
    "        person_1_poses = filtered_output[0::2, :, :]\n",
    "        person_2_poses = filtered_output[1::2, :, :]\n",
    "    else:\n",
    "        person_1_poses = []\n",
    "        person_2_poses = []\n",
    "        for i, frame in enumerate(filtered_output):\n",
    "            if i % 2 == 0:\n",
    "                person_1_poses.append(frame['pred_xyz_jts'])\n",
    "            else:\n",
    "                person_2_poses.append(frame['pred_xyz_jts'])\n",
    "        person_1_poses = np.array(person_1_poses)\n",
    "        person_2_poses = np.array(person_2_poses)\n",
    "    \n",
    "    poses_1_x = person_1_poses[:, :, 2]\n",
    "    poses_1_y = person_1_poses[:, :, 0]\n",
    "    poses_1_z = -person_1_poses[:, :, 1]\n",
    "    \n",
    "    poses_2_x = person_2_poses[:, :, 2]\n",
    "    poses_2_y = person_2_poses[:, :, 0]\n",
    "    poses_2_z = -person_2_poses[:, :, 1]\n",
    "    \n",
    "    def update(frame):\n",
    "        scatt1._offsets3d = (poses_1_x[frame], poses_1_y[frame], poses_1_z[frame])\n",
    "        scatt2._offsets3d = (poses_2_x[frame], poses_2_y[frame], poses_2_z[frame])\n",
    "    \n",
    "        for line, (start, end) in zip(lines1, skeleton):\n",
    "            line.set_data([poses_1_x[frame, start], poses_1_x[frame, end]], [poses_1_y[frame, start], poses_1_y[frame, end]])\n",
    "            line.set_3d_properties([poses_1_z[frame, start], poses_1_z[frame, end]])\n",
    "    \n",
    "        for line, (start, end) in zip(lines2, skeleton):\n",
    "            line.set_data([poses_2_x[frame, start], poses_2_x[frame, end]], [poses_2_y[frame, start], poses_2_y[frame, end]])\n",
    "            line.set_3d_properties([poses_2_z[frame, start], poses_2_z[frame, end]])\n",
    "        \n",
    "        return [scatt1, scatt2] + lines1 + lines2\n",
    "\n",
    "    plt.close(fig)\n",
    "    return FuncAnimation(fig, update, frames=range(len(poses_1_x)), interval=interval, blit=False)\n",
    "\n",
    "ani = animation(filtered_output[10500:10800])\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(len(filtered_output)/2)-1):\n",
    "    if filtered_output[i * 2]['idx'] > filtered_output[i * 2 + 1]['idx']:\n",
    "        print('Captured Inversion!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(len(filtered_output)/2)-1):\n",
    "    person_1 = np.array(filtered_output[i * 2]['pred_xyz_jts'])\n",
    "    to_compare_1 = np.array(filtered_output[(i + 1) * 2]['pred_xyz_jts'])\n",
    "    to_compare_2 = np.array(filtered_output[(i + 1) * 2 + 1]['pred_xyz_jts'])\n",
    "    \n",
    "    distance_1 = np.sum(np.linalg.norm(person_1 - to_compare_1))\n",
    "    distance_2 = np.sum(np.linalg.norm(person_1 - to_compare_2))\n",
    "\n",
    "    if distance_1 > distance_2:\n",
    "        change_order_aux = filtered_output[(i+1)*2+1].copy()\n",
    "        filtered_output[(i + 1) * 2 + 1] = filtered_output[(i + 1) * 2]\n",
    "        filtered_output[(i + 1) * 2] = change_order_aux\n",
    "\n",
    "        filtered_output[(i + 1) * 2]['idx'] = 1\n",
    "        filtered_output[(i + 1) * 2 + 1]['idx'] = 2\n",
    "\n",
    "ani = animation(filtered_output[10500:10800])\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "person_1_poses = []\n",
    "person_2_poses = []\n",
    "\n",
    "for i, frame in enumerate(filtered_output):\n",
    "    if i % 2 == 0:\n",
    "        person_1_poses.append(frame['pred_xyz_jts'])\n",
    "    else:\n",
    "        person_2_poses.append(frame['pred_xyz_jts'])\n",
    "person_1_poses = np.array(person_1_poses)\n",
    "person_2_poses = np.array(person_2_poses)\n",
    "\n",
    "# Savitzky-Golay filter\n",
    "def savgol_smoothness(poses, wl=11, po=3):\n",
    "    smoothed_data = np.zeros_like(poses)\n",
    "    \n",
    "    for joint in range(poses.shape[1]):\n",
    "        for axis in range(3):\n",
    "            smoothed_data[:, joint, axis] = savgol_filter(poses[:, joint, axis], wl, po)\n",
    "\n",
    "    return smoothed_data\n",
    "\n",
    "smoothed_data_1 = savgol_smoothness(person_1_poses)\n",
    "smoothed_data_2 = savgol_smoothness(person_2_poses)\n",
    "\n",
    "interleaved_array = np.zeros((2*smoothed_data_1.shape[0], smoothed_data_1.shape[1], smoothed_data_1.shape[2]))\n",
    "interleaved_array[0::2] = smoothed_data_1\n",
    "interleaved_array[1::2] = smoothed_data_2\n",
    "\n",
    "print(\"###############################################################################################\")\n",
    "print(\"#################################### Savitzky-Golay Filter ####################################\")\n",
    "print(\"###############################################################################################\")\n",
    "ani = animation(interleaved_array[10500:10800], np_flag=True)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "# Discrete cosine transform\n",
    "def dct_smoothness(poses, threshold=0.25):\n",
    "    smoothed_data = np.zeros_like(poses)\n",
    "    \n",
    "    for joint in range(poses.shape[1]):\n",
    "        for axis in range(3):\n",
    "            frequency_data = dct(poses[:, joint, axis], norm='ortho')\n",
    "            \n",
    "            frequency_data[int(threshold*len(frequency_data)):] = 0\n",
    "            \n",
    "            smoothed_data[:, joint, axis] = idct(frequency_data, norm='ortho')\n",
    "\n",
    "    return smoothed_data\n",
    "\n",
    "smoothed_data_1 = dct_smoothness(person_1_poses)\n",
    "smoothed_data_2 = dct_smoothness(person_2_poses)\n",
    "interleaved_array[0::2] = smoothed_data_1\n",
    "interleaved_array[1::2] = smoothed_data_2\n",
    "\n",
    "print(\"###################################################################################################\")\n",
    "print(\"#################################### Discrete Cosine Transform ####################################\")\n",
    "print(\"###################################################################################################\")\n",
    "ani = animation(interleaved_array[10500:10800], np_flag=True)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"processed_img_9085.npy\", interleaved_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
