{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "point_labels = [\n",
    "    'pelvis', 'left_hip', 'right_hip',      # 2\n",
    "    'spine1', 'left_knee', 'right_knee',    # 5\n",
    "    'spine2', 'left_ankle', 'right_ankle',  # 8\n",
    "    'spine3', 'left_foot', 'right_foot',    # 11\n",
    "    'neck', 'left_collar', 'right_collar',  # 14\n",
    "    'jaw',                                  # 15\n",
    "    'left_shoulder', 'right_shoulder',      # 17\n",
    "    'left_elbow', 'right_elbow',            # 19\n",
    "    'left_wrist', 'right_wrist',            # 21\n",
    "    'left_thumb', 'right_thumb',\n",
    "    'head', 'left_middle', 'right_middle',  # 26\n",
    "    'left_bigtoe', 'right_bigtoe'\n",
    "]\n",
    "\n",
    "skeleton_lines = [\n",
    "    #  ( (start group), (end group) ),\n",
    "    (('pelvis',), ('left_hip',)),\n",
    "    (('pelvis',), ('right_hip',)),\n",
    "    (('left_hip',), ('left_knee',)), \n",
    "    (('right_hip',), ('right_knee',)),\n",
    "    (('left_knee',), ('left_ankle',)), \n",
    "    (('right_knee',), ('right_ankle',)),\n",
    "    (('left_ankle',), ('left_foot',)),\n",
    "    (('right_ankle',), ('right_foot',)),\n",
    "    (('pelvis',), ('spine1',)), \n",
    "    (('spine1',), ('spine2',)),\n",
    "    (('spine2',), ('spine3',)),\n",
    "    (('spine3',), ('neck',)),\n",
    "    (('spine3',), ('left_collar',)),\n",
    "    (('spine3',), ('right_collar',)),\n",
    "    (('neck',), ('jaw',)),\n",
    "    (('left_collar',), ('left_shoulder',)),\n",
    "    (('right_collar',), ('right_shoulder',)),\n",
    "    (('left_shoulder',), ('left_elbow',)),\n",
    "    (('right_shoulder',), ('right_elbow',)),\n",
    "    (('left_elbow',), ('left_wrist',)),\n",
    "    (('right_elbow',), ('right_wrist',)),\n",
    "    (('left_wrist',), ('left_thumb',)),\n",
    "    (('right_wrist',), ('right_thumb',)),\n",
    "    (('neck',), ('head',)),\n",
    "    \n",
    "    # (('left_shoulder',), ('left_middle',)),\n",
    "    # (('right_shoulder',), ('right_middle',)),\n",
    "    (('left_ankle',), ('left_bigtoe',)),\n",
    "    (('right_ankle',), ('right_bigtoe',)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "import matplotlib\n",
    "from matplotlib import animation\n",
    "from mpl_toolkits.mplot3d.art3d import juggle_axes\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "ffmpeg_path = '/global/homes/z/zxwang11/ffmpeg-static/ffmpeg-7.0.1-amd64-static/ffmpeg'\n",
    "plt.rcParams['animation.ffmpeg_path'] = ffmpeg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skeleton_idxs = []\n",
    "for g1, g2 in skeleton_lines:\n",
    "    entry = []\n",
    "    entry.append([point_labels.index(l) for l in g1])\n",
    "    entry.append([point_labels.index(l) for l in g2])\n",
    "    skeleton_idxs.append(entry)\n",
    "\n",
    "# Cloud of every point connected:\n",
    "cloud_idxs = []\n",
    "for i in range(29):\n",
    "    for j in range(29):\n",
    "        entry = []\n",
    "        entry.append([i])\n",
    "        entry.append([j])\n",
    "        cloud_idxs.append(entry)\n",
    "\n",
    "all_idxs = skeleton_idxs + cloud_idxs\n",
    "\n",
    "def get_line_segments(seq, zcolor=None, cmap=None, cloud=False, edge_types=None, edge_class=None):\n",
    "    xline = np.zeros((seq.shape[0], len(all_idxs), 3, 2))\n",
    "    if cmap:\n",
    "        colors = np.zeros((len(all_idxs), 4))\n",
    "    for edge, (joint1, joint2) in enumerate(all_idxs):\n",
    "        xline[:, edge, :,0] = np.mean(seq[:, joint1], axis=1)\n",
    "        xline[:, edge, :,1] = np.mean(seq[:, joint2], axis=1)    \n",
    "        if cmap:\n",
    "            if edge_types is not None:\n",
    "                if edge >= len(skeleton_idxs): # cloud edges\n",
    "                    if edge_types[edge - len(skeleton_idxs), edge_class] == 1:\n",
    "                        colors[edge] = cmap(1)\n",
    "                    else:\n",
    "                        colors[edge] = cmap(0)\n",
    "            else:\n",
    "                colors[edge] = cmap(0)\n",
    "    if cmap:\n",
    "        return xline, colors\n",
    "    else:\n",
    "        return xline\n",
    "    \n",
    "# put line segments on the given axis, with given colors\n",
    "def put_lines(ax, segments, color=None, lw=2.5, alpha=None, skeleton=True, skeleton_alpha=0.3, cloud=False, cloud_alpha=0.03, threshold=0, edge_types=None, edge_opacities=None, edge_class=None):\n",
    "    lines = []\n",
    "    ### Main skeleton\n",
    "    for i in tqdm(range(len(skeleton_idxs)), desc=\"Skeleton lines\"):\n",
    "        if isinstance(color, (list, tuple, np.ndarray)):\n",
    "            c = color[i]\n",
    "        else:\n",
    "            c = color\n",
    "                        \n",
    "        if skeleton: alpha = skeleton_alpha\n",
    "        else: alpha = 0\n",
    "            \n",
    "        ### THESE LINES PLOT THE MAIN SKELETON\n",
    "        l = ax.plot(np.linspace(segments[i, 0, 0],segments[i, 0, 1], 2),\n",
    "                np.linspace(segments[i, 1, 0], segments[i, 1, 1], 2),\n",
    "                np.linspace(segments[i, 2, 0], segments[i, 2, 1], 2),\n",
    "                # color=c,\n",
    "                alpha=alpha,\n",
    "                lw=lw)[0]\n",
    "        lines.append(l)\n",
    "    \n",
    "    if cloud:\n",
    "        ### Cloud of all-connected joints\n",
    "        for i in tqdm(range(len(cloud_idxs)), desc=\"Cloud lines\"):\n",
    "            if isinstance(color, (list, tuple, np.ndarray)):\n",
    "                c = color[i]\n",
    "            else:\n",
    "                c = color\n",
    "                \n",
    "            l = ax.plot(\n",
    "                np.linspace(segments[i, 0, 0], segments[i, 0, 1], 2),\n",
    "                np.linspace(segments[i, 1, 0], segments[i, 1, 1], 2),\n",
    "                np.linspace(segments[i, 2, 0], segments[i, 2, 1], 2),\n",
    "                color=c,\n",
    "                alpha=cloud_alpha,\n",
    "                lw=lw)[0]\n",
    "            lines.append(l)\n",
    "    return lines\n",
    "\n",
    "# animate a video of the stick figure.\n",
    "# `ghost` may be a second sequence, which will be superimposed on the primary sequence.\n",
    "# If ghost_shift is given, the primary and ghost sequence will be separated laterally by that amount.\n",
    "# `zcolor` may be an N-length array, where N is the number of vertices in seq, and will be used to color the vertices. Typically this is set to the avg. z-value of each vtx.\n",
    "def animate_stick(seq, ghost=None, ghost_shift=0, threshold=0, figsize=None, zcolor=None, pointer=None, ax_lims=(-0.4, 0.4), speed=45, dot_size=20, dot_alpha=0.5, lw=2.5, cmap='cool_r', pointer_color='black', cloud=False, cloud_alpha=0.03, skeleton=True, skeleton_alpha=0.3):\n",
    "    if zcolor is None:\n",
    "        zcolor = np.zeros(seq.shape[1])\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    # ax = p3.Axes3D(fig)\n",
    "    ax = plt.axes(projection='3d')\n",
    "    \n",
    "    # The following lines eliminate background lines/axes:\n",
    "    ax.axis('on')\n",
    "    ax.xaxis.set_visible(True)\n",
    "    ax.yaxis.set_visible(True)\n",
    "    # ax.set_frame_on(True)\n",
    "    \n",
    "    # set figure background opacity (alpha) to 0:\n",
    "    fig.patch.set_alpha(0.)\n",
    "    \n",
    "    if ghost_shift and ghost is not None:\n",
    "        seq = seq.copy()\n",
    "        ghost = ghost.copy()\n",
    "        seq[:, :, 0] -= ghost_shift\n",
    "        ghost[:, :, 0] += ghost_shift\n",
    "    \n",
    "    cm = matplotlib.colormaps[cmap]\n",
    "\n",
    "    dot_color = \"black\"\n",
    "    pts = ax.scatter(seq[0, :, 0], seq[0, :, 1], seq[0, :, 2], c=dot_color, s=dot_size, alpha=dot_alpha)\n",
    "    ghost_color = 'blue'\n",
    "\n",
    "    if ghost is not None:\n",
    "        pts_g = ax.scatter(ghost[0, :, 0], ghost[0, :, 1], ghost[0, :, 2], c=ghost_color, s=dot_size, alpha=dot_alpha)\n",
    "    \n",
    "    if ax_lims:\n",
    "        ax.set_xlim(*ax_lims)\n",
    "        ax.set_ylim(*ax_lims)\n",
    "        ax.set_zlim(*ax_lims)\n",
    "    \n",
    "    plt.close(fig)\n",
    "    xline, colors = get_line_segments(seq, zcolor, cm)\n",
    "    lines = put_lines(ax, xline[0], color=colors, lw=lw, alpha=0.9, cloud=cloud, cloud_alpha=cloud_alpha, threshold=threshold, skeleton=skeleton, skeleton_alpha=skeleton_alpha)\n",
    "    \n",
    "    if ghost is not None:\n",
    "        xline_g = get_line_segments(ghost)\n",
    "        lines_g = put_lines(ax, xline_g[0], ghost_color, lw=lw, alpha=1.0, cloud=cloud, cloud_alpha=cloud_alpha, skeleton=skeleton, skeleton_alpha=skeleton_alpha)\n",
    "    \n",
    "    if pointer is not None:\n",
    "        vR = 0.15\n",
    "        dX, dY = vR * np.cos(pointer), vR * np.sin(pointer)\n",
    "        zidx = point_labels.index('CLAV')\n",
    "        X = seq[:, zidx, 0]\n",
    "        Y = seq[:, zidx, 1]\n",
    "        Z = seq[:, zidx, 2]\n",
    "        quiv = ax.quiver(X[0], Y[0], Z[0], dX[0], dY[0], 0, color=pointer_color)\n",
    "        ax.quiv = quiv\n",
    "    \n",
    "    def update(t):\n",
    "        pts._offsets3d = juggle_axes(seq[t, :, 0], seq[t, :, 1], seq[t, :, 2], 'z')\n",
    "        for i,l in enumerate(lines):\n",
    "            if l is not None:\n",
    "                l.set_data(xline[t, i, :2])\n",
    "                l.set_3d_properties(xline[t, i, 2])\n",
    "        \n",
    "        if ghost is not None:\n",
    "            pts_g._offsets3d = juggle_axes(ghost[t, :, 0], ghost[t, :, 1], ghost[t, :, 2], 'z')\n",
    "            for i, l in enumerate(lines_g):\n",
    "                l.set_data(xline_g[t, i, :2])\n",
    "                l.set_3d_properties(xline_g[t, i, 2])\n",
    "        \n",
    "        if pointer is not None:\n",
    "            ax.quiv.remove()\n",
    "            ax.quiv = ax.quiver(X[t], Y[t], Z[t], dX[t], dY[t], 0, color=pointer_color)\n",
    "    \n",
    "    return animation.FuncAnimation(\n",
    "        fig,\n",
    "        update,\n",
    "        len(seq),\n",
    "        interval=speed,\n",
    "        blit=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import random\n",
    "\n",
    "from data.dataset_original import DancerDatasetOriginal\n",
    "from model.model_pipeline import Pipeline\n",
    "from model.transformer import DancerTransformer\n",
    "\n",
    "def preprocess_dataset(dancer_np):\n",
    "    dancer1_np = dancer_np[::2, :, :]\n",
    "    dancer2_np = dancer_np[1::2, :, :]\n",
    "    return dancer1_np, dancer2_np\n",
    "\n",
    "\n",
    "def create_test_dataset(dataset_dir):\n",
    "    dancer_np = np.load('dataset/' + dataset_dir)\n",
    "    dancer1_np, dancer2_np = preprocess_dataset(dancer_np)\n",
    "    dataset = DancerDatasetOriginal(torch.from_numpy(dancer1_np), torch.from_numpy(dancer2_np), 64)\n",
    "\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    test_dataset = Subset(dataset, range(train_size, len(dataset)))\n",
    "\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1916\n",
      "torch.Size([64, 29, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "seq_length = 64\n",
    "test_set_idx = 1000\n",
    "\n",
    "test_dataset = create_test_dataset('pose_extraction_img_9085.npy')\n",
    "print(len(test_dataset))\n",
    "test_dict_data = test_dataset[test_set_idx]\n",
    "test_dict_data_next_timestamap = test_dataset[test_set_idx + seq_length]\n",
    "\n",
    "# [seq_len, 29, 3]\n",
    "dancer1_data = test_dict_data['dancer1'].to(device)\n",
    "dancer2_data = test_dict_data['dancer2'].to(device)\n",
    "\n",
    "print(dancer1_data.shape)\n",
    "\n",
    "dancer1_data_next_timestamp = test_dict_data_next_timestamap['dancer1'].to(device)\n",
    "dancer2_data_next_timestamp = test_dict_data_next_timestamap['dancer2'].to(device)\n",
    "\n",
    "# 128 frames\n",
    "dancer1_data_all = torch.cat((dancer1_data, dancer1_data_next_timestamp), dim=0)\n",
    "dancer2_data_all = torch.cat((dancer2_data, dancer2_data_next_timestamp), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_771916/2086760462.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d1_all = torch.tensor(dancer1_data_all[None, :], dtype=torch.float32)\n",
      "/tmp/ipykernel_771916/2086760462.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d2_all = torch.tensor(dancer2_data_all[None, :], dtype=torch.float32)\n",
      "/tmp/ipykernel_771916/2086760462.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d1 = torch.tensor(dancer1_data[None, :], dtype=torch.float32)\n",
      "/tmp/ipykernel_771916/2086760462.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d2 = torch.tensor(dancer2_data[None, :], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 29, 3])\n",
      "torch.Size([1, 64, 29, 3])\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline(64, 8, 32, 32, 64, 0.1, 0.2, 5e-5)\n",
    "net = DancerTransformer(64, 8, 64, 64, 64, 0.1).to(device)\n",
    "model.load_network(net, \"result/best_model_fea_64_head_8_latent_64_units_64_seq_len_64_prob_0.1_velo_0.2_kl_5e-05_mse_0.5.pth\")\n",
    "\n",
    "# test\n",
    "# 128 frames\n",
    "d1_all = torch.tensor(dancer1_data_all[None, :], dtype=torch.float32)\n",
    "d2_all = torch.tensor(dancer2_data_all[None, :], dtype=torch.float32)\n",
    "\n",
    "# 64 frames\n",
    "d1 = torch.tensor(dancer1_data[None, :], dtype=torch.float32)\n",
    "d2 = torch.tensor(dancer2_data[None, :], dtype=torch.float32)\n",
    "\n",
    "# \n",
    "with torch.no_grad():\n",
    "    vae_1, vae_2, vae_duet, transformer_decoder_1, transformer_decoder_2 = net.vae_1, net.vae_2, net.vae_duet, net.transformer_decoder_1, net.transformer_decoder_2\n",
    "\n",
    "    for i in range(64):\n",
    "        # [1, 64, 29, 3]\n",
    "        combined = torch.stack((d1_all[:, i: i + seq_length, :, :], d2[:, i: i + seq_length, :, :]), dim=-1)\n",
    "        # combined = torch.stack((d1[:, i: i + seq_length, :, :], d2_all[:, i: i + seq_length, :, :]), dim=-1)\n",
    "        mean = combined.mean(dim=(2, 3, 4), keepdim=True)\n",
    "        std = combined.std(dim=(2, 3, 4), keepdim=True)\n",
    "        combined_normalized = (combined - mean) / (std + 1e-6)\n",
    "\n",
    "        d1_normalized = combined_normalized[..., 0]\n",
    "        d2_normalized = combined_normalized[..., 1]\n",
    "\n",
    "        out_1, mean_1, log_var_1 = vae_1(d1_normalized)\n",
    "        out_2, mean_2, log_var_2 = vae_2(d2_normalized)\n",
    "        out_duet, mean_duet, log_var_duet = vae_duet(d1_normalized, d2_normalized)\n",
    "\n",
    "        # [batch_size, seq_len, 29 * 3]\n",
    "        memory_1 = out_1 + out_duet\n",
    "        memory_2 = out_2 + out_duet\n",
    "\n",
    "        # transformer decoder [1, 64, 29, 3]\n",
    "        pred_2 = transformer_decoder_1(d2_normalized, memory_1)\n",
    "        # pred_1 = transformer_decoder_2(d1_normalized, memory_2)\n",
    "\n",
    "        last_dim = pred_2[:, -1, :, :].unsqueeze(1)\n",
    "        d2 = torch.cat((d2, last_dim), dim=1)\n",
    "\n",
    "        # last_dim = pred_1[:, -1, :, :].unsqueeze(1)\n",
    "        # d1 = torch.cat((d1, last_dim), dim=1)\n",
    "\n",
    "print(dancer1_data_all.shape)\n",
    "print(d1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3798256 -1.1348479\n"
     ]
    }
   ],
   "source": [
    "seq1_original = dancer1_data_all[..., [2, 0, 1]]\n",
    "seq1_original[..., 2] = -seq1_original[..., 2]\n",
    "\n",
    "seq2_original = dancer2_data_all[..., [2, 0, 1]]\n",
    "seq2_original[..., 2] = -seq2_original[..., 2]\n",
    "\n",
    "seq1_next_ts = d1[0][..., [2, 0, 1]]\n",
    "seq1_next_ts[..., 2] = -seq1_next_ts[..., 2]\n",
    "\n",
    "seq2_next_ts = d2[0][..., [2, 0, 1]]\n",
    "seq2_next_ts[..., 2] = -seq2_next_ts[..., 2]\n",
    "\n",
    "seq1_original = seq1_original.cpu().numpy()\n",
    "\n",
    "seq2_next_ts = seq2_next_ts.cpu().numpy()\n",
    "print(np.max(seq2_next_ts), np.min(seq2_next_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ani = animate_stick(seq1_original, \n",
    "                    # ghost=seq2_next_ts, \n",
    "                    # ghost_shift=-0.2,\n",
    "                    figsize=(10, 8), \n",
    "                    speed=100,\n",
    "                    cmap='inferno', \n",
    "                    cloud=False,\n",
    "                    ax_lims=(-1.4, 2.5)\n",
    "    )\n",
    "\n",
    "display(HTML(ani.to_html5_video()))\n",
    "ani.save('animation1_1.gif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.1.0",
   "language": "python",
   "name": "pytorch-2.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
