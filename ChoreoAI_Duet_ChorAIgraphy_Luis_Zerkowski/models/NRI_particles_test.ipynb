{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b093c44-6eb7-484e-bb31-6203cf3d5b3b",
   "metadata": {},
   "source": [
    "## Exploring Particles Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b6a3f-6fcd-4248-a6f6-94af1d481d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Loading data\n",
    "loc_train = np.load('../../NRI/data/loc_train_charged5.npy')\n",
    "vel_train = np.load('../../NRI/data/vel_train_charged5.npy')\n",
    "edges_train = np.load('../../NRI/data/edges_train_charged5.npy')\n",
    "\n",
    "# Sampling data for testing\n",
    "sample_percentage = 0.2\n",
    "loc_train = loc_train[:int(sample_percentage*loc_train.shape[0]), :-1]\n",
    "vel_train = vel_train[:int(sample_percentage*vel_train.shape[0]), :-1]\n",
    "edges_train = edges_train[:int(sample_percentage*edges_train.shape[0])]\n",
    "\n",
    "print('Location shape: {}'.format(loc_train.shape))\n",
    "print('Velocity shape: {}'.format(vel_train.shape))\n",
    "print('Edges shape: {}'.format(edges_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64aa1f2-60cd-425e-ae7b-4533cd172e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "color_scales = [\n",
    "    mcolors.LinearSegmentedColormap.from_list(\"red_scale\", [\"#FFCCCC\", \"#CC0000\"]),\n",
    "    mcolors.LinearSegmentedColormap.from_list(\"blue_scale\", [\"#CCCCFF\", \"#0000CC\"]),\n",
    "    mcolors.LinearSegmentedColormap.from_list(\"green_scale\", [\"#CCFFCC\", \"#006600\"]),\n",
    "    mcolors.LinearSegmentedColormap.from_list(\"orange_scale\", [\"#FFE5CC\", \"#FF6600\"]),\n",
    "    mcolors.LinearSegmentedColormap.from_list(\"black_scale\", [\"#CCCCCC\", \"#000000\"])\n",
    "]\n",
    "\n",
    "# Visualizing particles' trajectories\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_title('Trajectories')\n",
    "ax1.set_xlabel('X coordinate')\n",
    "ax1.set_ylabel('Y coordinate')\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticklabels([])\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_title('Graph Structure')\n",
    "ax2.set_xticklabels([])\n",
    "ax2.set_yticklabels([])\n",
    "\n",
    "rand_seq = np.random.randint(0, loc_train.shape[0])\n",
    "colors = ['red', 'blue', 'green', 'orange', 'black']\n",
    "edge_pos = [(0, 0), (2, 0), (-0.5, 1), (1, 2), (2.5, 1)]\n",
    "seq_len = loc_train.shape[1]\n",
    "for i, e, c, cs in zip(range(len(edge_pos)), edge_pos, colors, color_scales):\n",
    "    for seq_idx in range(seq_len):\n",
    "        intensity = seq_idx / (seq_len - 1)\n",
    "        ax1.scatter(loc_train[rand_seq, seq_idx, 0, i], loc_train[rand_seq, seq_idx, 1, i], color=cs(intensity), s=50)\n",
    "        \n",
    "    ax2.scatter(e[0], e[1], color=c, s=100)\n",
    "    for j in range(len(edge_pos)):\n",
    "        if edges_train[rand_seq][i, j] == 1:\n",
    "            ax2.plot([edge_pos[i][0], edge_pos[j][0]], [edge_pos[i][1], edge_pos[j][1]], color='grey')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dde200-14eb-4b04-b1f0-2587a641ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating initial transposed edge index (adjacencies)\n",
    "edge_index_t = [[i, j] for i in range(5) for j in range(5)]\n",
    "\n",
    "# Visualizing connections for a random frame\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_title('Frame with connections')\n",
    "ax1.set_xlabel('X coordinate')\n",
    "ax1.set_ylabel('Y coordinate')\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticklabels([])\n",
    "\n",
    "rand_seq = np.random.randint(0, loc_train.shape[0])\n",
    "rand_frame = np.random.randint(0, loc_train.shape[1])\n",
    "colors = ['red', 'blue', 'green', 'orange', 'black']\n",
    "for p, c in zip(loc_train.swapaxes(0, 3), colors):\n",
    "    ax1.scatter(p[rand_frame, 0, rand_seq], p[rand_frame, 1, rand_seq], color=c)\n",
    "    \n",
    "for i, j in edge_index_t:\n",
    "    p_ini = [loc_train[rand_seq, rand_frame, 0, i], loc_train[rand_seq, rand_frame, 0, j]]\n",
    "    p_end = [loc_train[rand_seq, rand_frame, 1, i], loc_train[rand_seq, rand_frame, 1, j]]\n",
    "    ax1.plot(p_ini, p_end, color='grey')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac39636-0f5d-4c45-b9d5-eea032bfd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Adjusting training shapes for our current architecture\n",
    "train_batches = torch.cat([torch.tensor(loc_train.swapaxes(3, 2), dtype=torch.float32), \\\n",
    "                           torch.tensor(vel_train.swapaxes(3, 2), dtype=torch.float32)], axis=-1)\n",
    "\n",
    "sim_len = train_batches.size(1)\n",
    "seq_len = 6\n",
    "train_batches = train_batches.view(-1, seq_len, train_batches.size(2), train_batches.size(3))\n",
    "\n",
    "print('Final shape of training data: {}'.format(train_batches.shape))\n",
    "\n",
    "# Repeating data loading process for validation data\n",
    "loc_val = np.load('../../NRI/data/loc_valid_charged5.npy')\n",
    "loc_val = loc_val[:int(sample_percentage*loc_val.shape[0]), :-1]\n",
    "\n",
    "vel_val = np.load('../../NRI/data/vel_valid_charged5.npy')\n",
    "vel_val = vel_val[:int(sample_percentage*vel_val.shape[0]), :-1]\n",
    "\n",
    "edges_val = np.load('../../NRI/data/edges_valid_charged5.npy')\n",
    "edge_val = edges_val[:int(sample_percentage*edges_val.shape[0])]\n",
    "\n",
    "val_batches = torch.cat([torch.tensor(loc_val.swapaxes(3, 2), dtype=torch.float32), \\\n",
    "                         torch.tensor(vel_val.swapaxes(3, 2), dtype=torch.float32)], axis=-1)\n",
    "val_batches = val_batches.view(-1, seq_len, val_batches.size(2), val_batches.size(3))\n",
    "print('Final shape of validation data: {}'.format(val_batches.shape))\n",
    "\n",
    "batches = torch.cat([train_batches, val_batches], axis=0)\n",
    "print('Final shape of entire data: {}'.format(batches.shape))\n",
    "\n",
    "# Sending everything to the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_batches = train_batches.to(device)\n",
    "val_batches = val_batches.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773865e-c717-4606-863a-1bcafaf1cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building overlapping sequences dataset\n",
    "train_batches_ovlp = torch.cat([torch.tensor(loc_train.swapaxes(3, 2), dtype=torch.float32), \\\n",
    "                                torch.tensor(vel_train.swapaxes(3, 2), dtype=torch.float32)], axis=-1)\n",
    "train_batches_ovlp_aux = []\n",
    "for sample in train_batches_ovlp:\n",
    "    \n",
    "    train_batches_ovlp_aux2 = []\n",
    "    for start in range(sample.shape[0]-seq_len):\n",
    "        train_batches_ovlp_aux2.append(sample[start:start+seq_len])\n",
    "\n",
    "    train_batches_ovlp_aux.append(torch.stack(train_batches_ovlp_aux2))\n",
    "\n",
    "train_batches_ovlp = torch.cat(train_batches_ovlp_aux, dim=0)\n",
    "print('Final shape of training data for overlapping sequences: {}'.format(train_batches_ovlp.shape))\n",
    "\n",
    "val_batches_ovlp = torch.cat([torch.tensor(loc_val.swapaxes(3, 2), dtype=torch.float32), \\\n",
    "                              torch.tensor(vel_val.swapaxes(3, 2), dtype=torch.float32)], axis=-1)\n",
    "val_batches_ovlp_aux = []\n",
    "for sample in val_batches_ovlp:\n",
    "    \n",
    "    val_batches_ovlp_aux2 = []\n",
    "    for start in range(sample.shape[0]-seq_len):\n",
    "        val_batches_ovlp_aux2.append(sample[start:start+seq_len])\n",
    "\n",
    "    val_batches_ovlp_aux.append(torch.stack(val_batches_ovlp_aux2))\n",
    "\n",
    "val_batches_ovlp = torch.cat(val_batches_ovlp_aux, dim=0)\n",
    "print('Final shape of validation data for overlapping sequences: {}'.format(val_batches_ovlp.shape))\n",
    "\n",
    "batches_ovlp = torch.cat([train_batches_ovlp, val_batches_ovlp], axis=0)\n",
    "print('Final shape of entire data for overlapping sequencecs: {}'.format(batches_ovlp.shape))\n",
    "\n",
    "train_batches_ovlp = train_batches_ovlp.to(device)\n",
    "val_batches_ovlp = val_batches_ovlp.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a578da3-009d-47df-a306-fa262a091b41",
   "metadata": {},
   "source": [
    "## Testing NRI Variant Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c4246-9ee0-45cf-a62e-5878f17e6088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Creating message passing matrices for receivers and senders - shape R^(E x N)\n",
    "def message_passing_matrices(n_joints, edge_index):\n",
    "    message_passing_in = torch.zeros((edge_index.size(1), n_joints))\n",
    "    message_passing_out = torch.zeros((edge_index.size(1), n_joints))\n",
    "\n",
    "    # Vectorizing message_passing matrices creation\n",
    "    edge_indices = torch.arange(edge_index.size(1))\n",
    "    message_passing_out[edge_indices, edge_index[0]] = 1.\n",
    "    message_passing_in[edge_indices, edge_index[1]] = 1.\n",
    "\n",
    "    return message_passing_in, message_passing_out\n",
    "\n",
    "\n",
    "# NRI VAE auxiliar functions to change between nodes and edges\n",
    "def node2edge(x, m_in, m_out):    \n",
    "    receivers = torch.matmul(m_in, x)\n",
    "    senders = torch.matmul(m_out, x)\n",
    "    edges = torch.cat([senders, receivers], dim=1)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def edge2node(x, m_in):\n",
    "    incoming = torch.matmul(m_in.t(), x)\n",
    "    \n",
    "    return incoming / incoming.size(0)\n",
    "\n",
    "\n",
    "# Gumbel-Softmax sampling function to allow for backpropagation with categorical distributions\n",
    "def gumbel_softmax_sample(logits, temp, hard=False):\n",
    "    y = F.gumbel_softmax(logits, tau=temp, hard=hard)\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "# Computing KL Divergence for categorical distribution\n",
    "def gumbel_softmax_kl_divergence(logits, log_prior, batch_size):\n",
    "    q_y = F.softmax(logits, dim=-1)\n",
    "    kl_div = q_y * (F.log_softmax(logits, dim=-1) - log_prior)\n",
    "\n",
    "    # Normalizing by the batch size and number of edges\n",
    "    return kl_div.sum() / (batch_size * logits.size(0))\n",
    "\n",
    "\n",
    "# Initializing reconstruction losses\n",
    "nll_gaussian = nn.GaussianNLLLoss(reduction='mean') # Gaussian NLL\n",
    "mse = nn.MSELoss(reduction='mean') # MSE\n",
    "\n",
    "\n",
    "# Implementing LSTM variant with GCN layers\n",
    "class gcn_lstm_cell(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(gcn_lstm_cell, self).__init__()\n",
    "\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        \n",
    "        # Rebuilding LSTM cell with GCN layers\n",
    "        self.gcn_i = GCNConv(n_in + n_out, n_out)\n",
    "        self.gcn_f = GCNConv(n_in + n_out, n_out)\n",
    "        self.gcn_o = GCNConv(n_in + n_out, n_out)\n",
    "        self.gcn_g = GCNConv(n_in + n_out, n_out)\n",
    "\n",
    "    def forward(self, x, h, c, edge_index):\n",
    "        # Concatenate input and hidden state\n",
    "        combined = torch.cat([x, h], dim=-1)\n",
    "        \n",
    "        # Compute gates\n",
    "        i = torch.sigmoid(self.gcn_i(combined, edge_index))\n",
    "        f = torch.sigmoid(self.gcn_f(combined, edge_index))\n",
    "        o = torch.sigmoid(self.gcn_o(combined, edge_index))\n",
    "        g = torch.tanh(self.gcn_g(combined, edge_index))\n",
    "        \n",
    "        # Compute new cell and hidden states\n",
    "        c_new = f*c + i*g\n",
    "        h_new = o*torch.tanh(c_new)\n",
    "        \n",
    "        return h_new, c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7170b4a-0581-45c9-8e7f-87d9dd973a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as geo_nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear, BatchNorm1d, Dropout\n",
    "\n",
    "# Defining NRI encoder\n",
    "class nri_encoder(nn.Module):\n",
    "    def __init__(self, device, n_joints, edge_index_t, n_in, n_hid, n_out, do_prob=0.):\n",
    "        super(nri_encoder, self).__init__()\n",
    "\n",
    "        # Computing edge index given transposed edge index\n",
    "        self.edge_index = torch.Tensor(edge_index_t).t().long().to(device)\n",
    "\n",
    "        # Computing the message passing matrices\n",
    "        self.m_in, self.m_out = message_passing_matrices(n_joints, self.edge_index)\n",
    "        self.m_in = self.m_in.to(device)\n",
    "        self.m_out = self.m_out.to(device)\n",
    "\n",
    "        # Defining the network itself interleaving GCN and MLP layers\n",
    "        self.conv1 = GCNConv(n_in, n_hid, node_dim=1).to(device)\n",
    "        \n",
    "        self.mlp1 = Linear(n_hid*2, n_hid).to(device)\n",
    "        self.bnorm1 = BatchNorm1d(n_hid).to(device)\n",
    "        self.dropout1 = Dropout(do_prob).to(device)\n",
    "        \n",
    "        self.conv2 = GCNConv(n_hid, n_hid, node_dim=1).to(device)\n",
    "        \n",
    "        # self.mlp2 = Linear(n_hid*3, n_hid).to(device)\n",
    "        self.mlp2 = Linear(n_hid*2, n_hid).to(device)\n",
    "        self.bnorm2 = BatchNorm1d(n_hid).to(device)\n",
    "        \n",
    "        self.fc_out = Linear(n_hid, n_out).to(device)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "            elif isinstance(m, GCNConv):\n",
    "                nn.init.xavier_normal_(m.lin.weight)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Rearranging shapes: [num_seqs, num_timesteps, num_atoms, num_dims] -> [num_seqs, num_atoms, num_timesteps*num_dims]\n",
    "        x = x.view(x.size(0), x.size(2), -1)\n",
    "\n",
    "        # Forward pass interleaving GCN layers, operations to switch from nodes to edges or vice-versa, and MLP layers\n",
    "        x = self.conv1(x, self.edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # edge_x = [node2edge(x_samp, self.m_in, self.m_out) for x_samp in x]\n",
    "        # x = torch.stack(edge_x)\n",
    "        \n",
    "        # x = self.mlp1(x)\n",
    "        # x = F.relu(x)\n",
    "\n",
    "        # x = x.permute(0, 2, 1)\n",
    "        # x = self.bnorm1(x)\n",
    "        # x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # x = self.dropout1(x)\n",
    "\n",
    "        # # Skip connection\n",
    "        # x_skip = x.clone()\n",
    "\n",
    "        # node_x = [edge2node(x_samp, self.m_in) for x_samp in x]\n",
    "        # x = torch.stack(node_x)\n",
    "        \n",
    "        x = self.conv2(x, self.edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        edge_x = [node2edge(x_samp, self.m_in, self.m_out) for x_samp in x]\n",
    "        x = torch.stack(edge_x)\n",
    "        \n",
    "        # x = torch.cat((x, x_skip), dim=2)\n",
    "        x = self.mlp2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.bnorm2(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461155d-7ba0-4c99-b7f3-3ab3c5014924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRI recurrent encoder\n",
    "class nri_rec_encoder(nn.Module):\n",
    "    def __init__(self, device, n_joints, edge_index_t, n_in, n_hid, n_out, do_prob=0.):\n",
    "        super(nri_rec_encoder, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # Computing edge index given transposed edge index\n",
    "        self.edge_index = torch.Tensor(edge_index_t).t().long().to(device)\n",
    "\n",
    "        # Computing the message passing matrices\n",
    "        self.m_in, self.m_out = message_passing_matrices(n_joints, self.edge_index)\n",
    "        self.m_in = self.m_in.to(device)\n",
    "        self.m_out = self.m_out.to(device)\n",
    "\n",
    "        # Defining the network itself starting with GRNN and then MLP layers\n",
    "        self.grnn = gcn_lstm_cell(n_in, n_hid).to(device)\n",
    "        \n",
    "        self.mlp1 = Linear(n_hid*2, n_hid).to(device)\n",
    "        self.fc_out = Linear(n_hid, n_out).to(device)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "            elif isinstance(m, GCNConv):\n",
    "                nn.init.xavier_normal_(m.lin.weight)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Rearranging shapes: [num_seqs, num_timesteps, num_atoms, num_dims]\n",
    "        num_seqs, num_timesteps, num_atoms, num_dims = x.shape\n",
    "\n",
    "        # Iterating through samples in the batch\n",
    "        h_batch = []\n",
    "        for x_b in x:\n",
    "            # Initializing cell and hidden states\n",
    "            h = torch.zeros(num_atoms, self.grnn.n_out).to(self.device)\n",
    "            c = torch.zeros(num_atoms, self.grnn.n_out).to(self.device)\n",
    "            \n",
    "            # Iterating through GRNN\n",
    "            for x_t in x_b:\n",
    "                h, c = self.grnn(x_t, h, c, self.edge_index)\n",
    "\n",
    "            h_batch.append(h)\n",
    "        h = torch.stack(h_batch)\n",
    "        \n",
    "        # Forward pass with an operation to switch from nodes to edges and MLP layers\n",
    "        edge_x = [node2edge(h_samp, self.m_in, self.m_out) for h_samp in h]\n",
    "        x = torch.stack(edge_x)\n",
    "        \n",
    "        x = self.mlp1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8ea88-9a4a-4844-bd56-0de3381369f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining NRI decoder\n",
    "class nri_decoder(nn.Module):\n",
    "    def __init__(self, device, n_in, n_hid, n_out, do_prob=0.):\n",
    "        super(nri_decoder, self).__init__()\n",
    "\n",
    "        # Defining the network itself interleaving GCN and MLP layers\n",
    "        self.conv1 = GCNConv(n_in, n_hid).to(device)\n",
    "        \n",
    "        self.mlp1 = Linear(n_hid*2, n_hid).to(device)\n",
    "        self.dropout1 = Dropout(do_prob).to(device)\n",
    "        \n",
    "        self.conv2 = GCNConv(n_hid, n_out).to(device)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "            elif isinstance(m, GCNConv):\n",
    "                nn.init.xavier_normal_(m.lin.weight)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "    def forward(self, x, edge_index, m_in, m_out):\n",
    "        # Rearranging shapes: [num_timesteps, num_atoms, num_dims] -> [num_atoms, num_timesteps*num_dims]\n",
    "        x = x.view(x.size(0), x.size(2), -1)\n",
    "\n",
    "        # Forward pass interleaving GCN layers, operations to switch from nodes to edges or vice-versa, and MLP layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = node2edge(x, m_in, m_out)\n",
    "        \n",
    "        x = self.mlp1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = edge2node(x, m_in)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4fbeee-5e28-4ca6-8893-ae1713de3480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRI recurrent decoder\n",
    "class nri_rec_decoder(nn.Module):\n",
    "    def __init__(self, device, n_in, n_hid, n_out, do_prob=0.):\n",
    "        super(nri_rec_decoder, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        # Defining the network itself starting with GRNN and then interleaving MLP and GCN layers\n",
    "        self.grnn = gcn_lstm_cell(n_in, n_hid).to(device)\n",
    "        \n",
    "        self.mlp1 = Linear(n_hid*2, n_hid).to(device)\n",
    "        self.dropout1 = Dropout(do_prob).to(device)\n",
    "        \n",
    "        self.conv1 = GCNConv(n_hid, n_out).to(device)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "            elif isinstance(m, GCNConv):\n",
    "                nn.init.xavier_normal_(m.lin.weight)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "    def forward(self, x, edge_index, m_in, m_out):\n",
    "        # [num_timesteps, num_atoms, num_dims]\n",
    "        num_timesteps, num_atoms, num_dims = x.shape\n",
    "        \n",
    "        # Initializing cell and hidden states\n",
    "        h = torch.zeros(num_atoms, self.grnn.n_out).to(self.device)\n",
    "        c = torch.zeros(num_atoms, self.grnn.n_out).to(self.device)\n",
    "        \n",
    "        # Iterating through GRNN\n",
    "        for x_t in x:\n",
    "            h, c = self.grnn(x_t, h, c, edge_index)\n",
    "\n",
    "        # Forward pass interleaving GCN layers, operations to switch from nodes to edges or vice-versa, and MLP layers\n",
    "        x = node2edge(h, m_in, m_out)\n",
    "        \n",
    "        x = self.mlp1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = edge2node(x, m_in)\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11ec8d-0843-41cf-bb24-40bb2e0bc688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining NRI VAE\n",
    "class nri_vae(nn.Module):\n",
    "    def __init__(self, device, n_joints, edge_index_t, n_in, n_hid, edge_types, n_out, tau, hard, do_prob=0., n_dims=6, num_cells=None):\n",
    "        super(nri_vae, self).__init__()\n",
    "\n",
    "        # Initializing encoder and decoder\n",
    "        if num_cells is None:\n",
    "            self.encoder = nri_encoder(device, n_joints, edge_index_t, n_in, n_hid, edge_types, do_prob)\n",
    "            self.decoder = nri_decoder(device, n_in, n_hid, n_out, do_prob)\n",
    "        else:\n",
    "            self.encoder = nri_encoder(device, n_joints, edge_index_t, n_in, n_hid, edge_types, do_prob)\n",
    "            # self.encoder = nri_rec_encoder(device, n_joints, edge_index_t, n_dims, n_hid, edge_types, do_prob)\n",
    "            self.decoder = nri_rec_decoder(device, n_dims, n_hid, n_out, do_prob)\n",
    "\n",
    "        # Saving variables that will be used by the forward pass\n",
    "        self.device = device\n",
    "        self.n_joints = n_joints\n",
    "        \n",
    "        self.tau = tau\n",
    "        self.hard = hard\n",
    "\n",
    "        self.edge_index_t = torch.Tensor(edge_index_t).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Computing logits for edges with encoder\n",
    "        logits = self.encoder(x)\n",
    "\n",
    "        # Sampling edge index classes using Gumbel-Softmax\n",
    "        y = gumbel_softmax_sample(logits, tau, hard)\n",
    "\n",
    "        # Getting sampled edges for every element in the batch\n",
    "        edge_index_dict = {i: [] for i in range(logits.size(0))}\n",
    "        edge_index_classes = torch.nonzero(y[:, :, -1])\n",
    "        for batch_element, edge in edge_index_classes:\n",
    "            edge_index_dict[batch_element.item()].append(edge.item())\n",
    "\n",
    "        recon_output = []\n",
    "        for k, v in edge_index_dict.items():\n",
    "            # Building edge_index for sampled edges\n",
    "            edge_index_samp = self.edge_index_t[v].t().long()\n",
    "\n",
    "            # Creating message passing matrices for decoder newly sampled edge index\n",
    "            decoder_m_in, decoder_m_out = message_passing_matrices(self.n_joints, edge_index_samp)\n",
    "            decoder_m_in = decoder_m_in.to(self.device)\n",
    "            decoder_m_out = decoder_m_out.to(self.device)\n",
    "\n",
    "            # Reconstructing sequences using decoder\n",
    "            recon_output.append(self.decoder(x[k], edge_index_samp, decoder_m_in, decoder_m_out))\n",
    "        \n",
    "        recon_output = torch.stack(recon_output)\n",
    "\n",
    "        return logits, recon_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39acb31-0ebf-4199-bd75-1c15c95ee6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel implementation of NRI VAE, but not used because it barely helped\n",
    "# import concurrent.futures as cf\n",
    "# from threading import Lock\n",
    "\n",
    "# class nri_vae_parallel(nn.Module):\n",
    "#     def __init__(self, device, n_joints, edge_index_t, n_in, n_hid, edge_types, n_out, tau, hard, do_prob=0., n_dims=6, num_cells=None):\n",
    "#         super(nri_vae_parallel, self).__init__()\n",
    "\n",
    "#         # Initializing encoder and decoder\n",
    "#         self.encoder = nri_encoder(device, n_joints, edge_index_t, n_in, n_hid, edge_types, do_prob)\n",
    "        \n",
    "#         if num_cells is None:\n",
    "#             self.decoder = nri_decoder(device, n_in, n_hid, n_out, do_prob)\n",
    "#         else:\n",
    "#             self.decoder = nri_rec_decoder(device, n_dims, n_hid, n_out, do_prob)\n",
    "\n",
    "#         # Saving variables that will be used by the forward pass\n",
    "#         self.device = device\n",
    "#         self.n_joints = n_joints\n",
    "        \n",
    "#         self.tau = tau\n",
    "#         self.hard = hard\n",
    "\n",
    "#         self.edge_index_t = torch.Tensor(edge_index_t).to(device)\n",
    "\n",
    "#     def individual_reconstruction(self, k, v, edge_index_t, n_joints, device, decoder, x):\n",
    "#         # Building edge_index for sampled edges\n",
    "#         edge_index_samp = self.edge_index_t[v].t().long()\n",
    "\n",
    "#         # Creating message passing matrices for decoder newly sampled edge index\n",
    "#         decoder_m_in, decoder_m_out = message_passing_matrices(self.n_joints, edge_index_samp)\n",
    "#         decoder_m_in = decoder_m_in.to(self.device)\n",
    "#         decoder_m_out = decoder_m_out.to(self.device)\n",
    "\n",
    "#         # Reconstructing sequences using decoder\n",
    "#         return k, decoder(x[k], edge_index_samp, decoder_m_in, decoder_m_out)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # Computing logits for edges with encoder\n",
    "#         logits = self.encoder(x)\n",
    "\n",
    "#         # Sampling edge index classes using Gumbel-Softmax\n",
    "#         y = gumbel_softmax_sample(logits, tau, hard)\n",
    "\n",
    "#         # Getting sampled edges for every element in the batch\n",
    "#         edge_index_dict = {i: [] for i in range(logits.size(0))}\n",
    "#         edge_index_classes = torch.nonzero(y[:, :, 1])\n",
    "#         for batch_element, edge in edge_index_classes:\n",
    "#             edge_index_dict[batch_element.item()].append(edge.item())\n",
    "\n",
    "#         recon_output = {}\n",
    "#         lock = Lock()\n",
    "\n",
    "#         with cf.ThreadPoolExecutor() as executor:\n",
    "#             future_to_key = {executor.submit(self.individual_reconstruction, k, v, self.edge_index_t, self.n_joints, \\\n",
    "#                                              self.device, self.decoder, x): k for k, v in edge_index_dict.items()}\n",
    "    \n",
    "#             for future in cf.as_completed(future_to_key):\n",
    "#                 k, result = future.result()\n",
    "#                 with lock:\n",
    "#                     recon_output[k] = result\n",
    "\n",
    "#         # Sorting by key to maintain the original order\n",
    "#         recon_output_ordered = [recon_output[k] for k in sorted(recon_output.keys())]\n",
    "#         recon_output = torch.stack(recon_output_ordered)\n",
    "        \n",
    "#         return logits, recon_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf5833-dd62-416d-b3c7-e832de398a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Initializing all the hyperparameters\n",
    "batch_size = batches.size(1)\n",
    "seq_len_in = batches.size(1)\n",
    "seq_len_out = 1\n",
    "n_joints = batches.size(2)\n",
    "dims = batches.size(3)\n",
    "\n",
    "hidden_dims = 32\n",
    "edge_types = 4\n",
    "\n",
    "tau = 0.5\n",
    "hard = True\n",
    "dropout = 0.1\n",
    "out_var = 5e-5\n",
    "\n",
    "prior = [0.4, 0.3, 0.2, 0.1]\n",
    "log_prior = torch.FloatTensor(np.log(prior)).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "epochs = 20\n",
    "lr = 5e-4\n",
    "lr_decay = 6\n",
    "gamma = 0.5\n",
    "\n",
    "# Initializing model\n",
    "model = nri_vae(device, n_joints, edge_index_t, seq_len_in*dims, hidden_dims, edge_types, seq_len_out*int(dims/2), \\\n",
    "                tau, hard, dropout, dims, seq_len_in)\n",
    "\n",
    "# model = nri_vae_parallel(device, n_joints, edge_index_t, seq_len_in*dims, hidden_dims, edge_types, seq_len_out*int(dims/2), \\\n",
    "#                          tau, hard, dropout, dims, seq_len_in)\n",
    "\n",
    "# Counting number of trainable parameters to compare to the dataset size\n",
    "print('Total number of trainable parameters: {}\\n'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "for n, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        print('Layer {} has {} trainbale parameters'.format(n, p.numel()))\n",
    "\n",
    "# Initializing optimizer and scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=lr_decay, gamma=gamma)\n",
    "\n",
    "# Initializing lists to save losses across iterations\n",
    "kl_train = []\n",
    "recon_train = []\n",
    "loss_train = []\n",
    "kl_val = []\n",
    "recon_val = []\n",
    "loss_val = []\n",
    "\n",
    "# Initializing variables to save best model\n",
    "best_val_loss = torch.inf\n",
    "best_epoch = 0\n",
    "\n",
    "# Model iteration function\n",
    "def model_iteration(model, optimizer, scheduler, batches, beta, mode='train', recon_mode='nll'):\n",
    "    t = time.time()\n",
    "    \n",
    "    kl_aux = []\n",
    "    recon_aux = []\n",
    "    loss_aux = []\n",
    "\n",
    "    if mode == 'train':\n",
    "        model.train()\n",
    "    elif mode == 'val':\n",
    "        model.eval()\n",
    "    \n",
    "    progress = 0.\n",
    "    for idx in range(batches.size(0)//batch_size - batch_size):\n",
    "        if idx > progress*batches.size(0)//batch_size:\n",
    "            print('Progress of training epoch: {:.1f}% in {:.2f}s'.format(progress*100, time.time()-t))\n",
    "            progress += 0.1\n",
    "\n",
    "        # Skipping last sequence of a simulation \n",
    "        if idx%(sim_len/seq_len) == seq_len-1:\n",
    "            continue\n",
    "        \n",
    "        if mode == 'train':\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        batch = batches[idx*batch_size:(idx+1)*batch_size]\n",
    "        \n",
    "        # Non-overlapping sequences\n",
    "        next_batch = batches[idx*batch_size+1:(idx+1)*batch_size+1]\n",
    "        \n",
    "        # # Overlapping sequences\n",
    "        # next_batch = batches[(idx+1)*batch_size:(idx+2)*batch_size]\n",
    "\n",
    "        logits, recon_output = model(batch)\n",
    "        kl_loss = gumbel_softmax_kl_divergence(logits, log_prior, batch_size)\n",
    "        recon_output = recon_output.view(batch_size, seq_len_out, n_joints, int(dims/2))\n",
    "\n",
    "        if recon_mode == 'nll':\n",
    "            var_tensor = torch.full(recon_output.shape, out_var, device=device)\n",
    "            recon_loss = nll_gaussian(recon_output, next_batch[:, :seq_len_out, :, :int(dims/2)], var_tensor)\n",
    "        \n",
    "        elif recon_mode == 'mse':\n",
    "            recon_loss = mse(recon_output, next_batch[:, :seq_len_out, :, :int(dims/2)])\n",
    "            \n",
    "        recon_loss = recon_loss / (recon_output.size(0) * recon_output.size(1) * recon_output.size(2))\n",
    "\n",
    "        if recon_mode == 'nll':\n",
    "            recon_coef = 0.001\n",
    "        elif recon_mode == 'mse':\n",
    "            recon_coef = 1\n",
    "            \n",
    "        loss = beta*kl_loss + recon_coef*recon_loss\n",
    "        # loss = recon_coef*recon_loss\n",
    "\n",
    "        if mode == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        kl_aux.append(kl_loss.item())\n",
    "        recon_aux.append(recon_coef*recon_loss.item())    \n",
    "        loss_aux.append(loss.data.item())\n",
    "        \n",
    "    del batch, next_batch, logits, kl_loss, recon_loss\n",
    "\n",
    "    kl_aux = torch.Tensor(kl_aux)\n",
    "    recon_aux = torch.Tensor(recon_aux)\n",
    "    loss_aux = torch.Tensor(loss_aux)\n",
    "    tqdm.write(f'Epoch: {epoch + 1:04d}, '\n",
    "               f'KL Loss ({mode}): {torch.mean(kl_aux):.4f}, '\n",
    "               f'Reconstruction Loss ({mode}): {torch.mean(recon_aux):.4f}, '\n",
    "               f'Combined Loss ({mode}): {torch.mean(loss_aux):.4f}, '\n",
    "               f'time: {time.time() - t:.4f}s')\n",
    "\n",
    "    if mode == 'train':\n",
    "        scheduler.step()\n",
    "\n",
    "    if mode == 'val':\n",
    "        global best_val_loss\n",
    "        global best_epoch\n",
    "        \n",
    "        if best_val_loss is torch.inf or torch.mean(loss_aux) < best_val_loss:    \n",
    "            best_val_loss = torch.mean(loss_aux)\n",
    "            best_epoch = epoch\n",
    "            \n",
    "            torch.save(model.state_dict(), 'best_weights/nri_particles_parameters.pt')\n",
    "            tqdm.write(f'Epoch: {epoch + 1:04d}, Saving best parameters!')\n",
    "\n",
    "    if recon_mode == 'nll':\n",
    "        del var_tensor\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return kl_aux, recon_aux, loss_aux\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(epochs), desc='Training Epochs'):\n",
    "    # Beta coefficient to handle KL-Divergence vanishing gradients and balance reconstruction loss\n",
    "    beta = epoch % int(epochs) / (epochs)\n",
    "\n",
    "    kl_aux, recon_aux, loss_aux = model_iteration(model, optimizer, scheduler, train_batches, beta, 'train', 'nll')\n",
    "    \n",
    "    kl_train.append(torch.mean(kl_aux))\n",
    "    recon_train.append(torch.mean(recon_aux))\n",
    "    loss_train.append(torch.mean(loss_aux))\n",
    "\n",
    "    del kl_aux, recon_aux, loss_aux\n",
    "\n",
    "    with torch.no_grad():\n",
    "        kl_aux, recon_aux, loss_aux = model_iteration(model, optimizer, scheduler, val_batches, beta, 'val', 'nll')\n",
    "    \n",
    "    kl_val.append(torch.mean(kl_aux))\n",
    "    recon_val.append(torch.mean(recon_aux))\n",
    "    loss_val.append(torch.mean(loss_aux))\n",
    "\n",
    "    del kl_aux, recon_aux, loss_aux\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce88999-9a5c-42f5-b84e-fb4464bce55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting training losses\n",
    "ax1 = fig.add_subplot(231)\n",
    "ax1.plot(kl_train, color='blue')\n",
    "\n",
    "ax1 = fig.add_subplot(232)\n",
    "ax1.plot(recon_train, color='blue')\n",
    "\n",
    "ax1 = fig.add_subplot(233)\n",
    "ax1.plot(loss_train, color='blue')\n",
    "\n",
    "# Plotting validation losses\n",
    "ax1 = fig.add_subplot(234)\n",
    "ax1.plot(kl_val, color='orange')\n",
    "\n",
    "ax1 = fig.add_subplot(235)\n",
    "ax1.plot(recon_val, color='orange')\n",
    "\n",
    "ax1 = fig.add_subplot(236)\n",
    "ax1.plot(loss_val, color='orange')\n",
    "\n",
    "# Adding column labels\n",
    "fig.text(0.22, 0.96, 'KL Loss', ha='center', fontsize=14)\n",
    "fig.text(0.53, 0.96, 'Reconstruction Loss', ha='center', fontsize=14)\n",
    "fig.text(0.85, 0.96, 'Combined Loss', ha='center', fontsize=14)\n",
    "\n",
    "# Adding row labels\n",
    "fig.text(0.02, 0.73, 'Training', va='center', rotation='vertical', fontsize=14)\n",
    "fig.text(0.02, 0.30, 'Validation', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0642762d-5921-431e-97aa-b5e9dccc6220",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d07db7-35cc-45b5-b070-2e67ec388d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading best model\n",
    "model.load_state_dict(torch.load('best_weights/nri_particles_parameters.pt'))\n",
    "\n",
    "# Getting predicted edges from a chosen simulation and chosen sequence\n",
    "sim_idx = 0\n",
    "seq_idx = 0\n",
    "idx = int(sim_len/seq_len)*sim_idx + seq_idx\n",
    "\n",
    "n_joints = train_batches.size(2)\n",
    "\n",
    "logits = model.encoder(train_batches[idx].unsqueeze(0)).squeeze(0)\n",
    "\n",
    "y = gumbel_softmax_sample(logits, tau, False)\n",
    "\n",
    "# Confidence threshold\n",
    "confidence = 0.95\n",
    "edge_index_classes = torch.where(y[:, -1] > confidence)[0]\n",
    "\n",
    "# Top % edges\n",
    "# percentage = 0.01\n",
    "# k = int(len(edge_index_t)*percentage)\n",
    "# edge_index_classes = torch.topk(y[:, -1], k)[1]\n",
    "\n",
    "edge_index_samp = torch.Tensor(edge_index_t).to(device)[edge_index_classes].t().long()\n",
    "print('Amount of edges sampled with confidence {}%: {}'.format(int(confidence*100), len(edge_index_classes)))\n",
    "# print('Top {}% edges: {}'.format(int(percentage*100), len(edge_index_classes)))\n",
    "\n",
    "# Getting reconstructed frame\n",
    "decoder_m_in, decoder_m_out = message_passing_matrices(n_joints, edge_index_samp)\n",
    "decoder_m_in = decoder_m_in.to(device)\n",
    "decoder_m_out = decoder_m_out.to(device)\n",
    "\n",
    "recon_output = model.decoder(train_batches[idx], \\\n",
    "                                 edge_index_samp, decoder_m_in, decoder_m_out)\n",
    "recon_output = recon_output.view(seq_len_out, n_joints, int(dims/2)).cpu().detach().numpy()\n",
    "\n",
    "if seq_len_out == 1:\n",
    "    recon_output = recon_output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78118dee-0e7c-4eab-9974-f21487471f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "color_scales = [\n",
    "    mcolors.LinearSegmentedColormap.from_list(\"red_scale\", [\"#FFCCCC\", \"#CC0000\"]),\n",
    "    mcolors.LinearSegmentedColormap.from_list(\"blue_scale\", [\"#CCCCFF\", \"#0000CC\"]),\n",
    "    mcolors.LinearSegmentedColormap.from_list(\"green_scale\", [\"#CCFFCC\", \"#006600\"]),\n",
    "    mcolors.LinearSegmentedColormap.from_list(\"orange_scale\", [\"#FFE5CC\", \"#FF6600\"]),\n",
    "    mcolors.LinearSegmentedColormap.from_list(\"black_scale\", [\"#CCCCCC\", \"#000000\"])\n",
    "]\n",
    "\n",
    "if seq_len_out == 1:\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "    ax1 = fig.add_subplot(321)\n",
    "    ax1.set_title('Original Trajectory')\n",
    "    ax1.set_xlabel('X coordinate')\n",
    "    ax1.set_ylabel('Y coordinate')\n",
    "    \n",
    "    ax2 = fig.add_subplot(322)\n",
    "    ax2.set_title('Original Subsequent Trajectory')\n",
    "    ax2.set_xlabel('X coordinate')\n",
    "    ax2.set_ylabel('Y coordinate')\n",
    "    \n",
    "    ax3 = fig.add_subplot(323)\n",
    "    ax3.set_title('Original Subsequent Frame')\n",
    "    ax3.set_xlabel('X coordinate')\n",
    "    ax3.set_ylabel('Y coordinate')\n",
    "    \n",
    "    ax4 = fig.add_subplot(324)\n",
    "    ax4.set_title('Reconstructed Subsequent Frame')\n",
    "    ax4.set_xlabel('X coordinate')\n",
    "    ax4.set_ylabel('Y coordinate')\n",
    "    \n",
    "    ax5 = fig.add_subplot(325)\n",
    "    ax5.set_title('Original Graph Structure')\n",
    "    ax5.set_xticks([])\n",
    "    ax5.set_yticks([])\n",
    "\n",
    "    ax6 = fig.add_subplot(326)\n",
    "    ax6.set_title('Predicted Graph Structure')\n",
    "    ax6.set_xticks([])\n",
    "    ax6.set_yticks([])\n",
    "\n",
    "    # Plotting trajectories and frames\n",
    "    for p, e, c, cs in zip(range(n_joints), edge_pos, colors, color_scales):\n",
    "        for i in range(seq_len):\n",
    "            intensity = i / (seq_len - 1)\n",
    "            ax1.scatter(train_batches[idx, i, p, 0].detach().cpu(), train_batches[idx, i, p, 1].detach().cpu(), \n",
    "                        color=cs(intensity), s=50)\n",
    "            ax2.scatter(train_batches[idx+1, i, p, 0].detach().cpu(), train_batches[idx+1, i, p, 1].detach().cpu(), \n",
    "                        color=cs(intensity), s=50)\n",
    "\n",
    "        ax3.scatter(train_batches[idx+1, 0, p, 0].detach().cpu(), train_batches[idx+1, 0, p, 1].detach().cpu(), color=c)\n",
    "        ax4.scatter(recon_output[p, 0], recon_output[p, 1], color=c)\n",
    "\n",
    "        ax5.scatter(e[0], e[1], color=c, s=100)\n",
    "        ax6.scatter(e[0], e[1], color=c, s=100)\n",
    "        \n",
    "        for j in range(n_joints):\n",
    "            if edges_train[sim_idx][p, j] == 1:\n",
    "                ax5.plot([edge_pos[p][0], edge_pos[j][0]], [edge_pos[p][1], edge_pos[j][1]], color='grey')\n",
    "\n",
    "    # Plotting predicted edges\n",
    "    for e in edge_index_samp.t():\n",
    "        ax6.plot([edge_pos[e[0]][0], edge_pos[e[1]][0]], [edge_pos[e[0]][1], edge_pos[e[1]][1]], color='grey')\n",
    "\n",
    "    # Highlighting points of frame to be reconstructed\n",
    "    xlim = ax2.get_xlim()\n",
    "    ylim = ax2.get_ylim()\n",
    "    width = (xlim[1] - xlim[0]) * 0.025\n",
    "    height = (ylim[1] - ylim[0]) * 0.055\n",
    "    for p in range(n_joints):\n",
    "        first_x = train_batches[idx+1, 0, p, 0].detach().cpu()\n",
    "        first_y = train_batches[idx+1, 0, p, 1].detach().cpu()\n",
    "        circle = plt.Circle((first_x, first_y), radius=1, color='purple', fill=False, linewidth=2, \n",
    "                            transform=ax2.transData)\n",
    "        circle.set_width(width)\n",
    "        circle.set_height(height)\n",
    "        ax2.add_patch(circle)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff093cf-74dd-42af-a0c1-c6530a7b6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing full sequence of predictions\n",
    "logits = model.encoder(train_batches[idx].unsqueeze(0)).squeeze(0)\n",
    "\n",
    "y = gumbel_softmax_sample(logits, tau, False)\n",
    "\n",
    "# Confidence threshold\n",
    "confidence = 0.95\n",
    "edge_index_classes = torch.where(y[:, 1] > confidence)[0]\n",
    "\n",
    "# Top % edges\n",
    "# percentage = 0.01\n",
    "# k = int(len(edge_index_t)*percentage)\n",
    "# edge_index_classes = torch.topk(y[:, 1], k)[1]\n",
    "\n",
    "edge_index_samp = torch.Tensor(edge_index_t).to(device)[edge_index_classes].t().long()\n",
    "print('Amount of edges sampled with confidence {}%: {}'.format(int(confidence*100), len(edge_index_classes)))\n",
    "# print('Top {}% edges: {}'.format(int(percentage*100), len(edge_index_classes)))\n",
    "\n",
    "# Getting reconstructed frame\n",
    "decoder_m_in, decoder_m_out = message_passing_matrices(n_joints, edge_index_samp)\n",
    "decoder_m_in = decoder_m_in.to(device)\n",
    "decoder_m_out = decoder_m_out.to(device)\n",
    "\n",
    "recon_outputs = []\n",
    "for i in range(seq_len):\n",
    "    recon_output = model.decoder(train_batches_ovlp[idx+i], \\\n",
    "                                 edge_index_samp, decoder_m_in, decoder_m_out)\n",
    "    recon_output = recon_output.view(seq_len_out, n_joints, int(dims/2))\n",
    "    \n",
    "    if seq_len_out == 1:\n",
    "        recon_output = recon_output.squeeze(0)\n",
    "\n",
    "    recon_outputs.append(recon_output)\n",
    "\n",
    "recon_outputs = torch.stack(recon_outputs).cpu().detach().numpy()\n",
    "\n",
    "# Visualizing predicted particles' trajectories and graph structure\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.set_title('Original Trajectories')\n",
    "ax1.set_xlabel('X coordinate')\n",
    "ax1.set_ylabel('Y coordinate')\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax2.set_title('Predicted Trajectories')\n",
    "ax2.set_xlabel('X coordinate')\n",
    "ax2.set_ylabel('Y coordinate')\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax3.set_title('Original Graph Structure')\n",
    "ax3.set_xticklabels([])\n",
    "ax3.set_yticklabels([])\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "ax4.set_title('Predicted Graph Structure')\n",
    "ax4.set_xticklabels([])\n",
    "ax4.set_yticklabels([])\n",
    "\n",
    "# Plotting trajectories\n",
    "for p, e, c, cs in zip(range(n_joints), edge_pos, colors, color_scales):\n",
    "    for i in range(seq_len):\n",
    "        intensity = i / (seq_len - 1)\n",
    "        ax1.scatter(train_batches_ovlp[idx, i, p, 0].cpu().detach(), train_batches_ovlp[idx, i, p, 1].cpu().detach(), \\\n",
    "                    color=cs(intensity), s=50)\n",
    "        ax2.scatter(recon_outputs[i, p, 0], recon_outputs[i, p, 1], color=cs(intensity), s=50)\n",
    "\n",
    "\n",
    "    ax3.scatter(e[0], e[1], color=c, s=100)\n",
    "    ax4.scatter(e[0], e[1], color=c, s=100)\n",
    "\n",
    "    for j in range(n_joints):\n",
    "        if edges_train[sim_idx][p, j] == 1:\n",
    "            ax3.plot([edge_pos[p][0], edge_pos[j][0]], [edge_pos[p][1], edge_pos[j][1]], color='grey')\n",
    "    \n",
    "# Plotting predicted edges\n",
    "for e in edge_index_samp.t():\n",
    "    ax4.plot([edge_pos[e[0]][0], edge_pos[e[1]][0]], [edge_pos[e[0]][1], edge_pos[e[1]][1]], color='grey')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9879ab-2901-4afa-a494-17ca1055c883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
